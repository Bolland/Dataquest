{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Web pages use HyperText Markup Language (HTML). HTML isn't a programming language like Python. It's a markup language with its own syntax and rules. When a Web browser like Chrome or Firefox downloads a Web page, it reads the HTML to determine how to render it and display it to you.\n",
    "\n",
    "## HTML basics\n",
    "\n",
    "HTML consists of tags. We open a tag like this:\n",
    "\n",
    "`<p>`\n",
    "\n",
    "\n",
    "We close a tag like this:\n",
    "\n",
    "\n",
    "`</p>`\n",
    "\n",
    "Read more here: \n",
    "* https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics\n",
    "* https://developer.mozilla.org/en-US/docs/Web/HTML/Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "content = response.content\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving HTML elements w/ BeautifulSoup\n",
    "\n",
    "Downloading the page is the easy part. Let's say that we want to get the text in the first paragraph. Now we need to parse the page and extract the information we want.\n",
    "\n",
    "We'll use the **[BeautifulSoup library](https://www.crummy.com/software/BeautifulSoup/) to parse the Web page** with Python. This library allows us to extract tags from an HTML document.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is some simple content for this page.\n",
      "A simple example page\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize the parser, and pass in the content we grabbed earlier.\n",
    "parser = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "\n",
    "# Get the body tag from the document.\n",
    "# Since we passed in the top level of the document to the parser, we need to pick a branch off of the root.\n",
    "# With BeautifulSoup, we can access branches by using tag types as attributes.\n",
    "body = parser.body\n",
    "\n",
    "# Get the p tag from the body.\n",
    "p = body.p\n",
    "\n",
    "# Print the text inside the p tag.\n",
    "# Text is a property that gets the inside text of a tag.\n",
    "print(p.text)\n",
    "\n",
    "#shorter version:\n",
    "title_text = parser.head.title.text\n",
    "print(title_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find_all\n",
    "\n",
    "While it's nice to use the tag type as a property, it's not always a very robust way to parse a document. It's usually better to be more explicit by using the `find_all` method. This method will **find all occurrences of a tag in the current element, and return a list**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is some simple content for this page.\n"
     ]
    }
   ],
   "source": [
    "parser = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Get a list of all occurrences of the body tag in the element.\n",
    "body = parser.find_all(\"body\")\n",
    "\n",
    "# Get the paragraph tag.\n",
    "p = body[0].find_all(\"p\")\n",
    "\n",
    "# Get the text.\n",
    "print(p[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple example page\n"
     ]
    }
   ],
   "source": [
    "# Shorter version to get the title text\n",
    "title_text = parser.find_all(\"head\")[0].find_all(\"title\")[0].text\n",
    "print(title_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element IDs\n",
    "HTML allows elements to have IDs. Because they are unique, we can use an ID to refer to a specific element.\n",
    "\n",
    "E.g.: https://dataquestio.github.io/web-scraping-pages/simple_ids.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                First paragraph.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "# Get the page content and set up a new parser.\n",
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple_ids.html\")\n",
    "content = response.content\n",
    "parser = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Pass in the ID attribute to only get the element with that specific ID.\n",
    "first_paragraph = parser.find_all(\"p\", id=\"first\")[0]\n",
    "print(first_paragraph.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                Second paragraph.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "second_paragraph_text = parser.find_all(\"p\", id=\"second\")[0].text\n",
    "print(second_paragraph_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "\n",
    "In HTML, elements can also have classes. Classes aren't globally unique. In other words, many different elements belong to the same class, usually because they share a common purpose or characteristic.\n",
    "\n",
    "For example, you may want to create three dividers to display three of your photographs. You can create a common look and feel for these dividers, such as a border and caption style.\n",
    "\n",
    "This is where classes come into play. You could create a class called \"gallery,\" define a style for it once using CSS (which we'll talk about soon), and then apply that class to all of the dividers you'll use to display photos. One element can even have multiple classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <div>\\n            <p class=\"inner-text\">\\n                First paragraph.\\n            </p>\\n            <p class=\"inner-text\">\\n                Second paragraph.\\n            </p>\\n        </div>\\n        <p class=\"outer-text\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>\\n        <p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>\\n    </body>\\n</html>'\n",
      "[<p class=\"inner-text\">\n",
      "                First paragraph.\n",
      "            </p>, <p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>]\n",
      "\n",
      "                Second paragraph.\n",
      "            \n",
      "\n",
      "\n",
      "                First outer paragraph.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://dataquestio.github.io/web-scraping-pages/simple_classes.html\")\n",
    "content = response.content\n",
    "parser = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "print(content)\n",
    "\n",
    "classes = parser.find_all(\"p\",class_=\"inner-text\")\n",
    "print(classes)\n",
    "\n",
    "\n",
    "second_inner_paragraph_text = parser.find_all(\"p\", class_=\"inner-text\")[1].text\n",
    "print(second_inner_paragraph_text)\n",
    "\n",
    "first_outer_paragraph_text = parser.find_all(\"p\", class_=\"outer-text\")[0].text\n",
    "print(first_outer_paragraph_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS Selectors\n",
    "\n",
    "**Cascading Style Sheets**, or CSS, is a language for adding styles to HTML pages. You may have noticed that our simple HTML pages from the past few screens didn't have any styling; all of the paragraphs had black text and the same font size. Most Web pages use CSS to display a lot more than basic black text.\n",
    "\n",
    "CSS uses **selectors** to add styles to the elements and classes of elements you specify. You can use selectors to add background colors, text colors, borders, padding, and many other style choices to the elements on HTML pages.\n",
    "\n",
    "\n",
    "\n",
    "### Tag based\n",
    "This CSS will make all of the text **inside all paragraphs** red:\n",
    "\n",
    "```CSS\n",
    "p{\n",
    "    color: red\n",
    " }\n",
    " ```\n",
    "\n",
    "### Tag + class based\n",
    "This CSS will make all of the text **inside all paragraphs with `inner-text`** red:\n",
    "\n",
    "```CSS\n",
    "p.inner-text{\n",
    "    color: red\n",
    " }\n",
    "```\n",
    " \n",
    " ### Tag + ID based\n",
    " This CSS will change the text color to red for any paragraphs that have the **ID `first`**. We select IDs with the pound or hash symbol (#):\n",
    "\n",
    "```CSS\n",
    "p#first{\n",
    "    color: red\n",
    " }\n",
    "```\n",
    " \n",
    "### ID / class only\n",
    "\n",
    "You can also style IDs and classes without using any specific tags. For example, this CSS will make the element with the **ID `first`** red (not just paragraphs):\n",
    "\n",
    "```CSS\n",
    "#first{\n",
    "    color: red\n",
    " }\n",
    "```\n",
    "\n",
    "\n",
    "This CSS will make any element with the **class `inner-text`** red:\n",
    "\n",
    "```CSS\n",
    ".inner-text{\n",
    "    color: red\n",
    " }\n",
    "```\n",
    "\n",
    "### Combinations / specificity\n",
    "\n",
    "Selectors can combine tags, classes and ids. Always the most specific selector is taken:\n",
    "See example: https://codepen.io/Bolland/pen/pZWrMP\n",
    "\n",
    "**CSS**\n",
    "```CSS\n",
    "\n",
    "p{\n",
    "    color: red;\n",
    "    font-weight:bold\n",
    " }\n",
    "\n",
    "p.inner{\n",
    "  color:blue;\n",
    "}\n",
    "\n",
    "p.inner#class-test{\n",
    "  color:green;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "**HTML**\n",
    "```HTML\n",
    "<p>p only</p>  // red text\n",
    "\n",
    "<p class=\"inner\">p and class</p> //blue text\n",
    "\n",
    "<p class=\"inner\" id=\"class-test\">p and class and id</p> // green text\n",
    "```\n",
    "\n",
    "### Using CSS selectors in BeautifulSoup\n",
    "\n",
    "We can use **BeautifulSoup's `.select` method** to work with CSS selectors. Here's the HTML we'll be working with on this screen:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"inner-text first-item\" id=\"first\">\n",
      "                First paragraph.\n",
      "            </p>, <p class=\"outer-text first-item\" id=\"second\">\n",
      "<b>\n",
      "                First outer paragraph.\n",
      "            </b>\n",
      "</p>]\n",
      "First item text: \n",
      "                First paragraph.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "#Get content\n",
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "content = response.content\n",
    "\n",
    "#print(content)\n",
    "\n",
    "#initialise BS4 parser\n",
    "parser = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "# Select all of the elements that have the first-item class.\n",
    "first_items = parser.select(\".first-item\")\n",
    "\n",
    "print(first_items)\n",
    "\n",
    "# Print the text of the first paragraph (the first element with the first-item class).\n",
    "print(\"First item text: \" + first_items[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                First outer paragraph.\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "                First outer paragraph.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_outer_text = parser.select(\".outer-text\")[0].text\n",
    "print(first_outer_text)\n",
    "\n",
    "second_text = parser.select(\"#second\")[0].text\n",
    "print(second_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS Nesting\n",
    "\n",
    "We can nest CSS selectors similar to the way HTML nests tags. For example, we could use selectors to find all of the paragraphs inside the body tag. Nesting is a very powerful technique that enables us to use CSS to do complex Web scraping tasks.\n",
    "\n",
    "This selector will target any **paragraph inside a `div` tag**:\n",
    "\n",
    "```CSS\n",
    "div p\n",
    "```\n",
    "\n",
    "This selector will target any **item inside a `div` tag that has the class `first-item`**:\n",
    "```CSS\n",
    "div .first-item\n",
    "```\n",
    "\n",
    "This one is even more specific. It selects **any item that's inside a `div` tag inside a `body` tag, but only if it also has the ID `#first`**:\n",
    "```CSS\n",
    "body div #first\n",
    "```\n",
    "\n",
    "### Example:\n",
    "https://dataquestio.github.io/web-scraping-pages/2014_super_bowl.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "53\n",
      "377\n"
     ]
    }
   ],
   "source": [
    "# Get the Superbowl box score data.\n",
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/2014_super_bowl.html\")\n",
    "content = response.content\n",
    "parser = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Find the number of turnovers the Seahawks committed.\n",
    "turnovers = parser.select(\"#turnovers\")[0]\n",
    "seahawks_turnovers = turnovers.select(\"td\")[1]\n",
    "seahawks_turnovers_count = seahawks_turnovers.text\n",
    "print(seahawks_turnovers_count)\n",
    "\n",
    "#Total Plays for the New England patriots_total_plays_count\n",
    "patriots_total_plays_count = parser.select(\"tr#total-plays\")[0].select(\"td\")[1].text\n",
    "print(patriots_total_plays_count)\n",
    "\n",
    "#Total Yards for the Seahawks\n",
    "seahawks_total_yards_count = parser.select(\"#total-yards\")[0].select(\"td\")[2].text\n",
    "print(seahawks_total_yards_count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
