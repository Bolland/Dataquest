{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Web pages use HyperText Markup Language (HTML). HTML isn't a programming language like Python. It's a markup language with its own syntax and rules. When a Web browser like Chrome or Firefox downloads a Web page, it reads the HTML to determine how to render it and display it to you.\n",
    "\n",
    "## HTML basics\n",
    "\n",
    "HTML consists of tags. We open a tag like this:\n",
    "\n",
    "`<p>`\n",
    "\n",
    "\n",
    "We close a tag like this:\n",
    "\n",
    "\n",
    "`</p>`\n",
    "\n",
    "Read more here: \n",
    "* https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics\n",
    "* https://developer.mozilla.org/en-US/docs/Web/HTML/Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "content = response.content\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving HTML elements w/ BeautifulSoup\n",
    "\n",
    "Downloading the page is the easy part. Let's say that we want to get the text in the first paragraph. Now we need to parse the page and extract the information we want.\n",
    "\n",
    "We'll use the **[BeautifulSoup library](https://www.crummy.com/software/BeautifulSoup/) to parse the Web page** with Python. This library allows us to extract tags from an HTML document.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is some simple content for this page.\n",
      "A simple example page\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize the parser, and pass in the content we grabbed earlier.\n",
    "parser = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "\n",
    "# Get the body tag from the document.\n",
    "# Since we passed in the top level of the document to the parser, we need to pick a branch off of the root.\n",
    "# With BeautifulSoup, we can access branches by using tag types as attributes.\n",
    "body = parser.body\n",
    "\n",
    "# Get the p tag from the body.\n",
    "p = body.p\n",
    "\n",
    "# Print the text inside the p tag.\n",
    "# Text is a property that gets the inside text of a tag.\n",
    "print(p.text)\n",
    "\n",
    "#shorter version:\n",
    "title_text = parser.head.title.text\n",
    "print(title_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find_all\n",
    "\n",
    "While it's nice to use the tag type as a property, it's not always a very robust way to parse a document. It's usually better to be more explicit by using the `find_all` method. This method will **find all occurrences of a tag in the current element, and return a list**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is some simple content for this page.\n"
     ]
    }
   ],
   "source": [
    "parser = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Get a list of all occurrences of the body tag in the element.\n",
    "body = parser.find_all(\"body\")\n",
    "\n",
    "# Get the paragraph tag.\n",
    "p = body[0].find_all(\"p\")\n",
    "\n",
    "# Get the text.\n",
    "print(p[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple example page\n"
     ]
    }
   ],
   "source": [
    "# Shorter version to get the title text\n",
    "title_text = parser.find_all(\"head\")[0].find_all(\"title\")[0].text\n",
    "print(title_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element IDs\n",
    "HTML allows elements to have IDs. Because they are unique, we can use an ID to refer to a specific element.\n",
    "\n",
    "E.g.: https://dataquestio.github.io/web-scraping-pages/simple_ids.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                First paragraph.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "# Get the page content and set up a new parser.\n",
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple_ids.html\")\n",
    "content = response.content\n",
    "parser = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Pass in the ID attribute to only get the element with that specific ID.\n",
    "first_paragraph = parser.find_all(\"p\", id=\"first\")[0]\n",
    "print(first_paragraph.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                Second paragraph.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "second_paragraph_text = parser.find_all(\"p\", id=\"second\")[0].text\n",
    "print(second_paragraph_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "\n",
    "In HTML, elements can also have classes. Classes aren't globally unique. In other words, many different elements belong to the same class, usually because they share a common purpose or characteristic.\n",
    "\n",
    "For example, you may want to create three dividers to display three of your photographs. You can create a common look and feel for these dividers, such as a border and caption style.\n",
    "\n",
    "This is where classes come into play. You could create a class called \"gallery,\" define a style for it once using CSS (which we'll talk about soon), and then apply that class to all of the dividers you'll use to display photos. One element can even have multiple classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <div>\\n            <p class=\"inner-text\">\\n                First paragraph.\\n            </p>\\n            <p class=\"inner-text\">\\n                Second paragraph.\\n            </p>\\n        </div>\\n        <p class=\"outer-text\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>\\n        <p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>\\n    </body>\\n</html>'\n",
      "[<p class=\"inner-text\">\n",
      "                First paragraph.\n",
      "            </p>, <p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>]\n",
      "\n",
      "                Second paragraph.\n",
      "            \n",
      "\n",
      "\n",
      "                First outer paragraph.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://dataquestio.github.io/web-scraping-pages/simple_classes.html\")\n",
    "content = response.content\n",
    "parser = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "print(content)\n",
    "\n",
    "classes = parser.find_all(\"p\",class_=\"inner-text\")\n",
    "print(classes)\n",
    "\n",
    "\n",
    "second_inner_paragraph_text = parser.find_all(\"p\", class_=\"inner-text\")[1].text\n",
    "print(second_inner_paragraph_text)\n",
    "\n",
    "first_outer_paragraph_text = parser.find_all(\"p\", class_=\"outer-text\")[0].text\n",
    "print(first_outer_paragraph_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS Selectors\n",
    "\n",
    "Continue: https://www.dataquest.io/m/54/web-scraping/7/css-selectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
